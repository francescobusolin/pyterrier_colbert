{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unavailable-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pyterrier as pt\n",
    "import ujson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "from colbert.modeling.inference import ModelInference\n",
    "from colbert.evaluation.loaders import load_colbert\n",
    "from pyterrier_colbert import load_checkpoint\n",
    "# monkeypatch to use our downloading version\n",
    "import colbert.evaluation.loaders\n",
    "\n",
    "colbert.evaluation.loaders.load_checkpoint = load_checkpoint\n",
    "colbert.evaluation.loaders.load_model.__globals__['load_checkpoint'] = load_checkpoint\n",
    "from colbert.utils.utils import print_message\n",
    "import pickle\n",
    "from colbert.indexing.index_manager import IndexManager\n",
    "from warnings import warn\n",
    "from colbert.modeling import colbert as CBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "united-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concrete-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_colbert.preprocessing import DatasetPreprocessor, TokenRemover, HFTokenizer, NLTKTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import ir_datasets, ir_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improved-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_colbert(args):\n",
    "    print_message(\"#> Loading model checkpoint.\")\n",
    "    colbert = CBERT.ColBERT.from_pretrained('bert-base-uncased',\n",
    "                                      query_maxlen=args.query_maxlen,\n",
    "                                      doc_maxlen=args.doc_maxlen,\n",
    "                                      dim=args.dim,\n",
    "                                      similarity_metric=args.similarity, mask_punctuation=args.mask_punctuation)\n",
    "    DEVICE = 'cuda:0' if faiss.get_num_gpus() > 0 else 'cpu'\n",
    "    colbert = colbert.to(DEVICE)\n",
    "    checkpoint = load_checkpoint(args.checkpoint, colbert)\n",
    "    colbert.eval()\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    return colbert, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-bible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "roman-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=\"http://www.dcs.gla.ac.uk/~craigm/colbert.dnn.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rough-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Object()\n",
    "args.similarity = 'cosine'\n",
    "args.dim = 128\n",
    "args.query_maxlen = 32\n",
    "args.doc_maxlen = 180\n",
    "args.checkpoint = checkpoint\n",
    "args.mask_punctuation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "innocent-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpiece = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "hf_tokenizer = HFTokenizer(tokenizer=wordpiece)\n",
    "nltk_tokenizer = NLTKTokenizer(tokenizer_type='treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aboriginal-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:22] #> Loading model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:28] #> Loading checkpoint http://www.dcs.gla.ac.uk/~craigm/colbert.dnn.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/busolin/miniconda3/envs/cleanbert/lib/python3.8/site-packages/torch/hub.py:513: UserWarning: Falling back to the old format < 1.6. This support will be deprecated in favor of default zipfile format introduced in 1.6. Please redo torch.save() to save it in the new zipfile format.\n",
      "  warnings.warn('Falling back to the old format < 1.6. This support will be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:42] #> checkpoint['epoch'] = 0\n",
      "[Mar 11, 14:22:42] #> checkpoint['batch'] = 44500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colbert, model_checkpoint = load_colbert(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "injured-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_datasets import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "democratic-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(docs_tsv='minimarco/msmarco-passage-trec-dl-2019-docs.tsv', queries_tsv='minimarco/msmarco-passage-trec-dl-2019-queries.tsv', qrels_trec='minimarco/msmarco-passage-trec-dl-2019-qrels.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "narrative-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_dataset = pt.datasets.IRDSDataset(irds_id='irds:minimarco', defer_load=True)\n",
    "irds_dataset._irds_ref = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-station",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "literary-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'])\n",
    "en_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt', 'stopwords/stopwords-punctuations.txt'])\n",
    "\n",
    "en2_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'], stopword_max_length=2)\n",
    "en2_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt', 'stopwords/stopwords-punctuations.txt'], stopword_max_length=2)\n",
    "\n",
    "en4_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'], stopword_max_length=4)\n",
    "en4_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt', 'stopwords/stopwords-punctuations.txt'], stopword_max_length=4)\n",
    "\n",
    "\n",
    "lim_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-limited.txt'])\n",
    "lim_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-limited.txt', 'stopwords/stopwords-punctuations.txt'])\n",
    "\n",
    "en2the_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'], stopword_max_length=2)\n",
    "en2the_remover.stopwords = en2the_remover.stopwords | set(['the'])\n",
    "\n",
    "en2the_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-limited.txt', 'stopwords/stopwords-punctuations.txt'], stopword_max_length=2)\n",
    "en2the_punc_remover.stopwords = en2the_punc_remover.stopwords | set(['the'])\n",
    "\n",
    "punc_only = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-punctuations.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fifty-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaners = [\n",
    "    ('en', en_remover),\n",
    "    ('enpunc', en_punc_remover),\n",
    "    ('en2', en2_remover),\n",
    "    ('en2punc', en2_punc_remover),\n",
    "    ('en2the', en2the_remover),\n",
    "    ('en2thepunc', en2the_punc_remover),\n",
    "    ('punc', punc_only),\n",
    "    #('en4', en4_remover) ,\n",
    "    #('en4punc', en4_punc_remover),\n",
    "    #('few', lim_remover),\n",
    "    #('fewpunc', lim_punc_remover)\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "split-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cleaned = {name: DatasetPreprocessor(dataset=irds_dataset, tokenizer=nltk_tokenizer, preprocessor=cleaner) for name, cleaner in cleaners}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controversial-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier_colbert.indexing\n",
    "import torch\n",
    "import os\n",
    "from pyterrier_colbert.ranking import ColBERTFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "impossible-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:43] #> Loading the FAISS index from ./indexes/index.base.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:43] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:43] len(self.emb2pid) = 716547\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.61shard/s]\n"
     ]
    }
   ],
   "source": [
    "retrievers = {}\n",
    "pyterrier_colbert_factory = ColBERTFactory((colbert, model_checkpoint), \"./indexes/\", \"index.base.minimarco\", faisstype='mmap')\n",
    "colbert_e2e = pyterrier_colbert_factory.end_to_end()\n",
    "retrievers['base'] = colbert_e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becoming-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_names = [t[0] for t in cleaners]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "supported-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:45] #> Loading the FAISS index from ./indexes/index.clean.en.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:45] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:45] len(self.emb2pid) = 482356\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.15shard/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:45] #> Loading the FAISS index from ./indexes/index.clean.enpunc.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:45] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:46] len(self.emb2pid) = 426165\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.99shard/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:46] #> Loading the FAISS index from ./indexes/index.clean.en2.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:47] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:47] len(self.emb2pid) = 629420\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.56shard/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:47] #> Loading the FAISS index from ./indexes/index.clean.en2punc.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:47] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:47] len(self.emb2pid) = 575290\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.55shard/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:48] #> Loading the FAISS index from ./indexes/index.clean.en2the.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:48] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:49] len(self.emb2pid) = 603554\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.89shard/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:49] #> Loading the FAISS index from ./indexes/index.clean.en2thepunc.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:49] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:49] len(self.emb2pid) = 562565\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.83shard/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 11, 14:22:50] #> Loading the FAISS index from ./indexes/index.clean.punc.minimarco/ivfpq.256.faiss ..\n",
      "[Mar 11, 14:22:50] #> Building the emb2pid mapping..\n",
      "[Mar 11, 14:22:50] len(self.emb2pid) = 660872\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86shard/s]\n"
     ]
    }
   ],
   "source": [
    "for name in cleaner_names:\n",
    "    factory = ColBERTFactory((colbert, model_checkpoint), f'./indexes', f'index.clean.{name}.minimarco', faisstype='mmap')\n",
    "    rete2e = factory.end_to_end()\n",
    "    retrievers[name] = rete2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "optional-reply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b67c6_row0_col1, #T_b67c6_row3_col1, #T_b67c6_row3_col2, #T_b67c6_row3_col3, #T_b67c6_row3_col4, #T_b67c6_row5_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b67c6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b67c6_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_b67c6_level0_col1\" class=\"col_heading level0 col1\" >ndcg_cut_10</th>\n",
       "      <th id=\"T_b67c6_level0_col2\" class=\"col_heading level0 col2\" >mrt</th>\n",
       "      <th id=\"T_b67c6_level0_col3\" class=\"col_heading level0 col3\" >ndcg_cut_10 +</th>\n",
       "      <th id=\"T_b67c6_level0_col4\" class=\"col_heading level0 col4\" >ndcg_cut_10 -</th>\n",
       "      <th id=\"T_b67c6_level0_col5\" class=\"col_heading level0 col5\" >ndcg_cut_10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b67c6_row0_col0\" class=\"data row0 col0\" >base</td>\n",
       "      <td id=\"T_b67c6_row0_col1\" class=\"data row0 col1\" >0.730000</td>\n",
       "      <td id=\"T_b67c6_row0_col2\" class=\"data row0 col2\" >265.670000</td>\n",
       "      <td id=\"T_b67c6_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_b67c6_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_b67c6_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b67c6_row1_col0\" class=\"data row1 col0\" >en</td>\n",
       "      <td id=\"T_b67c6_row1_col1\" class=\"data row1 col1\" >0.700000</td>\n",
       "      <td id=\"T_b67c6_row1_col2\" class=\"data row1 col2\" >218.490000</td>\n",
       "      <td id=\"T_b67c6_row1_col3\" class=\"data row1 col3\" >17.000000</td>\n",
       "      <td id=\"T_b67c6_row1_col4\" class=\"data row1 col4\" >22.000000</td>\n",
       "      <td id=\"T_b67c6_row1_col5\" class=\"data row1 col5\" >0.037490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b67c6_row2_col0\" class=\"data row2 col0\" >enpunc</td>\n",
       "      <td id=\"T_b67c6_row2_col1\" class=\"data row2 col1\" >0.690000</td>\n",
       "      <td id=\"T_b67c6_row2_col2\" class=\"data row2 col2\" >195.120000</td>\n",
       "      <td id=\"T_b67c6_row2_col3\" class=\"data row2 col3\" >13.000000</td>\n",
       "      <td id=\"T_b67c6_row2_col4\" class=\"data row2 col4\" >28.000000</td>\n",
       "      <td id=\"T_b67c6_row2_col5\" class=\"data row2 col5\" >0.013167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b67c6_row3_col0\" class=\"data row3 col0\" >en2</td>\n",
       "      <td id=\"T_b67c6_row3_col1\" class=\"data row3 col1\" >0.730000</td>\n",
       "      <td id=\"T_b67c6_row3_col2\" class=\"data row3 col2\" >189.440000</td>\n",
       "      <td id=\"T_b67c6_row3_col3\" class=\"data row3 col3\" >24.000000</td>\n",
       "      <td id=\"T_b67c6_row3_col4\" class=\"data row3 col4\" >14.000000</td>\n",
       "      <td id=\"T_b67c6_row3_col5\" class=\"data row3 col5\" >0.724551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b67c6_row4_col0\" class=\"data row4 col0\" >en2punc</td>\n",
       "      <td id=\"T_b67c6_row4_col1\" class=\"data row4 col1\" >0.710000</td>\n",
       "      <td id=\"T_b67c6_row4_col2\" class=\"data row4 col2\" >260.020000</td>\n",
       "      <td id=\"T_b67c6_row4_col3\" class=\"data row4 col3\" >18.000000</td>\n",
       "      <td id=\"T_b67c6_row4_col4\" class=\"data row4 col4\" >20.000000</td>\n",
       "      <td id=\"T_b67c6_row4_col5\" class=\"data row4 col5\" >0.062662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b67c6_row5_col0\" class=\"data row5 col0\" >en2the</td>\n",
       "      <td id=\"T_b67c6_row5_col1\" class=\"data row5 col1\" >0.730000</td>\n",
       "      <td id=\"T_b67c6_row5_col2\" class=\"data row5 col2\" >266.490000</td>\n",
       "      <td id=\"T_b67c6_row5_col3\" class=\"data row5 col3\" >23.000000</td>\n",
       "      <td id=\"T_b67c6_row5_col4\" class=\"data row5 col4\" >15.000000</td>\n",
       "      <td id=\"T_b67c6_row5_col5\" class=\"data row5 col5\" >0.678887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b67c6_row6_col0\" class=\"data row6 col0\" >en2thepunc</td>\n",
       "      <td id=\"T_b67c6_row6_col1\" class=\"data row6 col1\" >0.710000</td>\n",
       "      <td id=\"T_b67c6_row6_col2\" class=\"data row6 col2\" >265.000000</td>\n",
       "      <td id=\"T_b67c6_row6_col3\" class=\"data row6 col3\" >19.000000</td>\n",
       "      <td id=\"T_b67c6_row6_col4\" class=\"data row6 col4\" >20.000000</td>\n",
       "      <td id=\"T_b67c6_row6_col5\" class=\"data row6 col5\" >0.113418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b67c6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b67c6_row7_col0\" class=\"data row7 col0\" >punc</td>\n",
       "      <td id=\"T_b67c6_row7_col1\" class=\"data row7 col1\" >0.720000</td>\n",
       "      <td id=\"T_b67c6_row7_col2\" class=\"data row7 col2\" >261.300000</td>\n",
       "      <td id=\"T_b67c6_row7_col3\" class=\"data row7 col3\" >16.000000</td>\n",
       "      <td id=\"T_b67c6_row7_col4\" class=\"data row7 col4\" >23.000000</td>\n",
       "      <td id=\"T_b67c6_row7_col5\" class=\"data row7 col5\" >0.046621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f206d20a280>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    list(retrievers.values()),\n",
    "    irds_dataset.get_topics(),\n",
    "    irds_dataset.get_qrels(),\n",
    "    eval_metrics=[\"ndcg_cut_10\", 'mrt'],\n",
    "    names = list(retrievers.keys()),\n",
    "    baseline=0,\n",
    "    highlight='bold',\n",
    "    round=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-university",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-spare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cleanbert)",
   "language": "python",
   "name": "cleanbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
