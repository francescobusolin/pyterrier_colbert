{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pyterrier as pt\n",
    "import ujson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "from colbert.modeling.inference import ModelInference\n",
    "from colbert.evaluation.loaders import load_colbert\n",
    "from pyterrier_colbert import load_checkpoint\n",
    "# monkeypatch to use our downloading version\n",
    "import colbert.evaluation.loaders\n",
    "\n",
    "colbert.evaluation.loaders.load_checkpoint = load_checkpoint\n",
    "colbert.evaluation.loaders.load_model.__globals__['load_checkpoint'] = load_checkpoint\n",
    "from colbert.utils.utils import print_message\n",
    "import pickle\n",
    "from colbert.indexing.index_manager import IndexManager\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_colbert.preprocessing import DatasetPreprocessor, TokenRemover, HFTokenizer, NLTKTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import ir_datasets, ir_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=\"http://www.dcs.gla.ac.uk/~craigm/colbert.dnn.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Object()\n",
    "args.similarity = 'cosine'\n",
    "args.dim = 128\n",
    "args.query_maxlen = 32\n",
    "args.doc_maxlen = 180\n",
    "args.checkpoint = checkpoint\n",
    "args.mask_punctuation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpiece = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "hf_tokenizer = HFTokenizer(tokenizer=wordpiece)\n",
    "nltk_tokenizer = NLTKTokenizer(tokenizer_type='treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_datasets import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(docs_tsv='minimarco/msmarco-passage-trec-dl-2019-docs.tsv', queries_tsv='minimarco/msmarco-passage-trec-dl-2019-queries.tsv', qrels_trec='minimarco/msmarco-passage-trec-dl-2019-qrels.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_dataset = pt.datasets.IRDSDataset(irds_id='irds:minimarco', defer_load=True)\n",
    "irds_dataset._irds_ref = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_dataset.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'])\n",
    "en_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt', 'stopwords/stopwords-punctuations.txt'])\n",
    "\n",
    "en2_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'], stopword_max_length=2)\n",
    "en2_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt', 'stopwords/stopwords-punctuations.txt'], stopword_max_length=2)\n",
    "\n",
    "en4_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'], stopword_max_length=4)\n",
    "en4_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt', 'stopwords/stopwords-punctuations.txt'], stopword_max_length=4)\n",
    "\n",
    "\n",
    "lim_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-limited.txt'])\n",
    "lim_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-limited.txt', 'stopwords/stopwords-punctuations.txt'])\n",
    "\n",
    "en2the_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-en.txt'], stopword_max_length=2)\n",
    "en2the_remover.stopwords = en2the_remover.stopwords | set(['the'])\n",
    "\n",
    "en2the_punc_remover = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-limited.txt', 'stopwords/stopwords-punctuations.txt'], stopword_max_length=2)\n",
    "en2the_punc_remover.stopwords = en2the_punc_remover.stopwords | set(['the'])\n",
    "\n",
    "punc_only = TokenRemover(tokenizer=nltk_tokenizer, stopwords_files=['stopwords/stopwords-punctuations.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaners = [('en', en_remover),\n",
    "            ('enpunc', en_punc_remover),\n",
    "            ('en2', en2_remover),\n",
    "            ('en2punc', en2_punc_remover),\n",
    "            ('en2the', en2the_remover),\n",
    "            ('en2thepunc', en2the_punc_remover),\n",
    "            ('en4', en4_remover) ,\n",
    "            ('en4punc', en4_punc_remover),\n",
    "            ('few', lim_remover),\n",
    "            ('punc', punc_only),\n",
    "            ('fewpunc', lim_punc_remover)\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cleaned = {name: DatasetPreprocessor(dataset=irds_dataset, tokenizer=nltk_tokenizer, preprocessor=cleaner) for name, cleaner in cleaners}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier_colbert.indexing\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./indexes/index.base.minimarco/'):\n",
    "    base_indexer = pyterrier_colbert.indexing.ColBERTIndexer(checkpoint, \"./indexes\", \"index.base.minimarco\", chunksize=3, num_partitions=256)\n",
    "    base_indexer.index(irds_dataset.get_corpus_iter(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data_iter in datasets_cleaned.items():\n",
    "    if not os.path.exists(f'./indexes/index.clean.{name}.minimarco/'):\n",
    "        cleaned_indexer = pyterrier_colbert.indexing.ColBERTIndexer(checkpoint, f'./indexes', f'index.clean.{name}.minimarco', chunksize=3, num_partitions=256)\n",
    "        cleaned_indexer.index(data_iter)\n",
    "        clean_indexer = None\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('gg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-template",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-defeat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cleanbert)",
   "language": "python",
   "name": "cleanbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
